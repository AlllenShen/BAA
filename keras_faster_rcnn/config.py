import math
class Config:

    def __init__(self):

        self.verbose = False   #训练过程中是否打印信息

        # 基础CNN模型
        self.network = 'VGG16'

        # 数据增强
        self.use_horizontal_flips = False
        self.use_vertical_flips = False
        self.rot_90 = False

        # anchor box scales
        # self.anchor_box_scales = [64, 128, 256] # 手掌区域
        # self.anchor_box_scales = [40, 60, 80] # 指骨区域
        self.anchor_box_scales = [48, 60, 128] 

        # anchor box ratios
        # self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]
        self.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]] # 小标注框用这个命中更多
        # 需要调整的图片最小边的大小
        self.im_size = 600

        self.img_channel_mean = [103.939, 116.779, 123.68]
        self.img_scaling_factor = 1.0

        self.balanced_classes = False

        # 一次处理的roi个数  论文中是一次处理300个，但是太大了，容易导致OOM，改成32
        # self.num_rois = 300
        self.num_rois = 32

        #从原始图片到feature map对应的缩放比例 (这取决于基础网络模型，对于VGG16来说，就是16)
        self.rpn_stride = 16


        # scaling the stdev
        self.std_scaling = 4.0
        self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

        # overlaps for RPN
        self.rpn_min_overlap = 0.3
        self.rpn_max_overlap = 0.5

        # overlaps for classifier ROIs
        self.classifier_min_overlap = 0.1
        self.classifier_max_overlap = 0.5

        # placeholder for the class mapping, automatically generated by the parser
        self.class_mapping = None
        self.base_net_weights = "models/vgg16_weights_tf_dim_ordering_tf_kernels.h5"

        # self.model_path = 'models/wrist_frcnn.vgg.hdf5'
        # self.model_path = 'models/finger_frcnn.vgg.hdf5'
        self.model_path = 'models/model1_frcnn.vgg.hdf5'